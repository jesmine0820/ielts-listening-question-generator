{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95df638",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import json5\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import textstat\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63b05639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize genai\n",
    "genai.configure(api_key=\"AIzaSyBS-2pbdjYouOkcqHaX4ZI5HHPpSSmq3iw\")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializer\n",
    "QUESTION_TYPE_CSV = \"model_training/processed_data/questionType.csv\"\n",
    "TRAINING_CSV = \"model_training/processed_data/training_set.csv\"\n",
    "GENERATED_CSV = \"model_training/processed_data/generated_question.csv\"\n",
    "WORD_CSV = \"model_training/processed_data/ielts_vocab.csv\"\n",
    "\n",
    "MAX_ATTEMPT = 5\n",
    "REWARD_GOAL = 4\n",
    "\n",
    "assignments = {}\n",
    "questions = []\n",
    "\n",
    "question_type_df = pd.read_csv(QUESTION_TYPE_CSV)\n",
    "common_vocab_df = pd.read_csv(WORD_CSV)\n",
    "training_df = pd.read_csv(TRAINING_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce80b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Question TypeError\n",
    "def choose_question_type():\n",
    "    for section in sorted(question_type_df['part'].unique()):\n",
    "        section_types = question_type_df[question_type_df['part'] == section]['type'].tolist()\n",
    "        k = random.choice([1,2])\n",
    "        selected = random.sample(section_types, k=min(k,len(section_types)))\n",
    "        assignments[f\"Section {section}\"] = selected\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73efca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT TEMPLATE\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert IELTS Listening question generator.\n",
    "Generate a realistic IELTS Listening question according to the following details:\n",
    "\n",
    "Question Type: {typeID} - {type_name}\n",
    "Theme: {theme}\n",
    "Specific Topic: {specific_topic}\n",
    "Specifications: {specifications}\n",
    "Instructions: {instruction}\n",
    "Format: {format}\n",
    "Answer Format: {answer_format}\n",
    "Key Skills: {key_skills}\n",
    "Average Duration: {avg_duration}\n",
    "Average Script Length: {avg_script_length}\n",
    "Key Features: {key_features}\n",
    "Audio Speed: {audio_speed}\n",
    "\n",
    "Requirements:\n",
    "1. Generate questions, answers, and the audio transcript.\n",
    "2. If the question type requires a diagram (Map, Plan, Flow Chart), generate a simple diagram (as text description or URL placeholder).\n",
    "3. Return the output in JSON format:\n",
    "{{\n",
    "  \"Type\": [],\n",
    "  \"Instructions\": [],\n",
    "  \"Diagram\": [],\n",
    "  \"Questions\": [],\n",
    "  \"Answers\": [],\n",
    "  \"Transcript\": \"\"\n",
    "}}\n",
    "Type -> Question types with type names only\n",
    "Instructions -> Instructions for the question based on the references above\n",
    "Diagram -> Diagram description or URL placeholder (if applicable, else null)\n",
    "Questions -> List of questions\n",
    "Answers -> List of answers\n",
    "Transcript -> Full audio transcript. The transcript should include the introductions as a real IELTS Listening test. The length must between {avg_script_length}.\n",
    "4. Ensure the JSON is properly formatted. Do not include any explanations or additional text outside the JSON.\n",
    "5. Do not add other fields other than the ones mentioned in the JSON format above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b6e4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Function\n",
    "def calculate_readability_score(text):\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "def is_in_average_word_count(text, section):\n",
    "    def calculate_total_word_count():\n",
    "        nonlocal text\n",
    "        if isinstance(text, (list, pd.Series)):\n",
    "            text = \" \".join(map(str, text))\n",
    "\n",
    "        words = re.findall(r'\\b\\w+\\b', str(text))\n",
    "        return len(words)\n",
    "    \n",
    "    expected_ranges = {\n",
    "        \"Section 1\": (500, 700),\n",
    "        \"Section 2\": (600, 800),\n",
    "        \"Section 3\": (800, 1000),\n",
    "        \"Section 4\": (1000, 1200)\n",
    "    }\n",
    "\n",
    "    total_words = calculate_total_word_count()\n",
    "\n",
    "    low, high = expected_ranges[section]\n",
    "    return low <= total_words <= high\n",
    "\n",
    "def calculate_common_word_ratio(text):\n",
    "    common_vocab = set(common_vocab_df[\"Words\"].astype(str).str.lower().tolist())\n",
    "    \n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        return 0\n",
    "    \n",
    "    words = [w.lower() for w in re.findall(r'\\b\\w+\\b', str(text))]\n",
    "    if not words:\n",
    "        return 0\n",
    "    \n",
    "    uncommon = [w for w in words if w not in common_vocab]\n",
    "    return len(uncommon) / len(words)\n",
    "\n",
    "def calculate_similarity(text):\n",
    "    existing_texts = []\n",
    "\n",
    "    if 'transcript' in training_df.columns:\n",
    "        existing_texts += training_df['transcript'].dropna().astype(str).tolist()\n",
    "\n",
    "    if os.path.exists(GENERATED_CSV):\n",
    "        generated_df = pd.read_csv(GENERATED_CSV)\n",
    "        if 'Transcript' in generated_df.columns:\n",
    "            existing_texts += generated_df['Transcript'].dropna().astype(str).tolist()\n",
    "\n",
    "        if not existing_texts:\n",
    "            return 0.0\n",
    "    \n",
    "    corpus = existing_texts + [str(text)]\n",
    "\n",
    "    vectorizer = TfidfVectorizer().fit(corpus)\n",
    "    vectors = vectorizer.transform(corpus)\n",
    "\n",
    "    sim_scores = cosine_similarity(vectors[-1], vectors[:-1]).flatten()\n",
    "\n",
    "    max_sim = sim_scores.max() if len(sim_scores) > 0 else 0.0\n",
    "    return max_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d860b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Function\n",
    "def safe_json_parse(raw_text):\n",
    "    start = raw_text.find(\"{\")\n",
    "    end = raw_text.rfind(\"}\")\n",
    "    \n",
    "    if start == -1 or end == -1:\n",
    "        return None\n",
    "\n",
    "    json_block = raw_text[start:end+1]\n",
    "    cleaned = json_block\n",
    "    cleaned = cleaned.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    cleaned = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", cleaned)\n",
    "    cleaned = re.sub(r\",\\s*([\\]}])\", r\"\\1\", cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    try:\n",
    "        parsed = json5.loads(cleaned)\n",
    "        return parsed\n",
    "\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2430ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "def convert_to_df(questions):\n",
    "    def normalize_question(q):\n",
    "        if q is None:\n",
    "            return None\n",
    "        \n",
    "        clean = {}\n",
    "\n",
    "        clean['DateTime_Generated'] = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "        # Flatten Type\n",
    "        t = q.get(\"Type\")\n",
    "        if isinstance(t, list):\n",
    "            clean[\"Type\"] = \" \".join(str(x) for x in t)\n",
    "        else:\n",
    "            clean[\"Type\"] = t\n",
    "\n",
    "        # Flatten Instructions\n",
    "        instr = q.get(\"Instructions\")\n",
    "        if isinstance(instr, list):\n",
    "            clean[\"Instructions\"] = \" \".join(str(x) for x in instr)\n",
    "        else:\n",
    "            clean[\"Instructions\"] = instr\n",
    "\n",
    "        clean[\"Questions\"] = q.get(\"Questions\")\n",
    "        clean[\"Answers\"] = q.get(\"Answers\")\n",
    "        clean[\"Diagram\"] = q.get(\"Diagram\")\n",
    "        clean[\"Transcript\"] = q.get(\"Transcript\")\n",
    "\n",
    "        return clean\n",
    "    \n",
    "    return pd.DataFrame([normalize_question(q) for q in questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5114d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Question\n",
    "def generate_question_model(typeID, type_name, theme, specific_topic, specifications, instruction, answer_format, format, key_skills, avg_duration, avg_script_length, key_features, audio_speed):\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        typeID=typeID,\n",
    "        type_name=type_name,\n",
    "        theme=theme,\n",
    "        specific_topic=specific_topic,\n",
    "        specifications=specifications,\n",
    "        instruction=instruction,\n",
    "        answer_format=answer_format,\n",
    "        format=format,\n",
    "        key_skills=key_skills,\n",
    "        avg_duration=avg_duration,\n",
    "        avg_script_length=avg_script_length,\n",
    "        key_features=key_features,\n",
    "        audio_speed=audio_speed\n",
    "    )\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    clean_response = safe_json_parse(response.text)\n",
    "    \n",
    "    return clean_response\n",
    "\n",
    "def generate_question(theme, specific_topic, specifications):\n",
    "    assignments = choose_question_type()\n",
    "    for section, types in assignments.items():\n",
    "        print(f\"\\n{section} Questions:\")\n",
    "        for q_type in types:\n",
    "            type_info = question_type_df[question_type_df['type'] == q_type].iloc[0]\n",
    "\n",
    "            for x in range(MAX_ATTEMPT):\n",
    "                print(f\"  Try Attempt: {x}\")\n",
    "                question_data = generate_question_model(\n",
    "                    typeID=type_info['type'],\n",
    "                    type_name=type_info['type'],\n",
    "                    theme=theme,\n",
    "                    specific_topic=specific_topic,\n",
    "                    specifications=specifications,\n",
    "                    instruction=type_info['instruction'],\n",
    "                    answer_format=type_info['answer_format'],\n",
    "                    format=type_info['format'],\n",
    "                    key_skills=type_info['key_skills'],\n",
    "                    avg_duration=type_info['avg_duration'],\n",
    "                    avg_script_length=type_info['avg_script_length'],\n",
    "                    key_features=type_info['key_features'],\n",
    "                    audio_speed=type_info['audio_speed']\n",
    "                )\n",
    "                \n",
    "                temp_df = convert_to_df([question_data])\n",
    "                if 'Transcript' in temp_df.columns and pd.notna(temp_df['Transcript'].iloc[0]):\n",
    "                    transcript_text = temp_df['Transcript'].iloc[0]\n",
    "                    reability_score = calculate_readability_score(transcript_text)\n",
    "                    avg_word_length = is_in_average_word_count(transcript_text, section)\n",
    "                    common_word_ratio = calculate_common_word_ratio(transcript_text)\n",
    "                    similarity = calculate_similarity(transcript_text)\n",
    "                    reward = 0\n",
    "                else:\n",
    "                    transcript_text = \"\"\n",
    "                    reability_score = 0\n",
    "                    avg_word_length = False\n",
    "                    common_word_ratio = 0\n",
    "                    similarity = 0\n",
    "                    reward = 0\n",
    "\n",
    "                print(f\"    Current Score: {reability_score} | {avg_word_length} | {common_word_ratio} | {similarity}\")\n",
    "\n",
    "                # Calculate Reward\n",
    "                if reability_score >= 60:\n",
    "                    reward += 1\n",
    "                if avg_word_length:\n",
    "                    reward += 1\n",
    "                if common_word_ratio >= 0.1:\n",
    "                    reward += 1\n",
    "                if similarity <= 0.85:\n",
    "                    reward += 1\n",
    "\n",
    "                print(f\"    Current Reward: {reward}\")\n",
    "\n",
    "                if reward == REWARD_GOAL:\n",
    "                    break\n",
    "\n",
    "            questions.append(temp_df)\n",
    "\n",
    "    print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fffaa97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Section 1 Questions:\n",
      "  Try Attempt: 0\n",
      "    Current Score: 69.2639345751931 | True | 0.232796486090776 | 0.2142363932662911\n",
      "    Current Reward: 4\n",
      "  Try Attempt: 0\n",
      "    Current Score: 68.7967171717172 | True | 0.18381112984822934 | 0.34351552134962465\n",
      "    Current Reward: 4\n",
      "\n",
      "Section 2 Questions:\n",
      "  Try Attempt: 0\n",
      "    Current Score: 39.818968531468556 | False | 0.20739910313901344 | 0.31837327753051037\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 1\n",
      "    Current Score: 40.72762678621464 | True | 0.17516339869281045 | 0.3001272455400897\n",
      "    Current Reward: 3\n",
      "  Try Attempt: 2\n",
      "    Current Score: 58.54002908434461 | False | 0.16534541336353342 | 0.328482099657406\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 3\n",
      "    Current Score: 54.34096107902707 | False | 0.2064864864864865 | 0.31363538381727074\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 4\n",
      "    Current Score: 55.511538578656456 | False | 0.16607773851590105 | 0.32466555888600884\n",
      "    Current Reward: 2\n",
      "\n",
      "Section 3 Questions:\n",
      "  Try Attempt: 0\n",
      "    Current Score: 9.76034754672898 | False | 0.22492401215805471 | 0.30360225315629835\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 1\n",
      "    Current Score: 17.964172626142243 | True | 0.21728971962616822 | 0.29350236592319506\n",
      "    Current Reward: 3\n",
      "  Try Attempt: 2\n",
      "    Current Score: 20.033123087385263 | False | 0.24400564174894218 | 0.2473391970207186\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 3\n",
      "    Current Score: 7.288134715025933 | False | 0.19594594594594594 | 0.26036577986626264\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 4\n",
      "    Current Score: 14.593469387755135 | False | 0.20505992010652463 | 0.2893994889368053\n",
      "    Current Reward: 2\n",
      "\n",
      "Section 4 Questions:\n",
      "  Try Attempt: 0\n",
      "    Current Score: 17.743000000000023 | False | 0.23541666666666666 | 0.3256747497858675\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 1\n",
      "    Current Score: 29.800001566416057 | False | 0.20851528384279475 | 0.2763902680115183\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 2\n",
      "    Current Score: 13.30682828529558 | False | 0.2334152334152334 | 0.26627381369929093\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 3\n",
      "    Current Score: 9.38939520333679 | False | 0.2299084435401831 | 0.3167893668364186\n",
      "    Current Reward: 2\n",
      "  Try Attempt: 4\n",
      "    Current Score: 9.27736006322445 | False | 0.23171987641606592 | 0.2770707531681422\n",
      "    Current Reward: 2\n",
      "[  DateTime_Generated              Type  \\\n",
      "0   2025_11_29_18_11  Table Completion   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  Complete the table below. Write ONE WORD AND /...   \n",
      "\n",
      "                                           Questions  \\\n",
      "0  [1. Room _________, 2. _________ AM, 3. ______...   \n",
      "\n",
      "                                             Answers  \\\n",
      "0  [105, 9:00, calculator, Thursday, 1:00, essays...   \n",
      "\n",
      "                                             Diagram  \\\n",
      "0  ## University Lecture Schedule\\n\\n| Lecture Ti...   \n",
      "\n",
      "                                          Transcript  \n",
      "0  NARRATOR: You will hear a conversation between...  ,   DateTime_Generated             Type  \\\n",
      "0   2025_11_29_18_11  Form Completion   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  Complete the form below. Write ONE WORD AND / ...   \n",
      "\n",
      "                                           Questions  \\\n",
      "0  [University Lecture Series Registration Form, ...   \n",
      "\n",
      "                                     Answers Diagram  \\\n",
      "0  [8546, Sociology, Robotics, Tuesday, 305]    None   \n",
      "\n",
      "                                          Transcript  \n",
      "0  You will hear a conversation between a univers...  ,   DateTime_Generated           Type  \\\n",
      "0   2025_11_29_18_13  Map Labelling   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  Label the map below. Write the correct letter,...   \n",
      "\n",
      "                                           Questions          Answers  \\\n",
      "0  [1. Bookshop, 2. Post Office, 3. Careers Servi...  [C, B, G, F, I]   \n",
      "\n",
      "                                             Diagram  \\\n",
      "0  \\n                  North\\n                   ...   \n",
      "\n",
      "                                          Transcript  \n",
      "0  You will hear a university staff member giving...  ,   DateTime_Generated                               Type  \\\n",
      "0   2025_11_29_18_14  Multiple Choice - Multiple Choice   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  You will hear a part of a university lecture a...   \n",
      "\n",
      "                                           Questions Answers Diagram  \\\n",
      "0  [What TWO significant challenges does the lect...  [B, D]    None   \n",
      "\n",
      "                                          Transcript  \n",
      "0  Examiner: You will hear a part of a university...  ,   DateTime_Generated                 Type  \\\n",
      "0   2025_11_29_18_16  Sentence Completion   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  Complete the sentences below. Write NO MORE TH...   \n",
      "\n",
      "                                           Questions  \\\n",
      "0  [1. The traditional lecture format is often cr...   \n",
      "\n",
      "                                             Answers Diagram  \\\n",
      "0  [passive reception, critical thinking, interac...    None   \n",
      "\n",
      "                                          Transcript  \n",
      "0  You will hear a lecture from a university prof...  ]\n"
     ]
    }
   ],
   "source": [
    "# Main Pipeline\n",
    "theme = \"Education\"\n",
    "specific_topic = \"University Lectures\"\n",
    "specifications = \"Academic context, formal tone\"\n",
    "\n",
    "generate_question(theme, specific_topic, specifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28d98662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[  DateTime_Generated              Type  \\\n",
       " 0   2025_11_29_18_11  Table Completion   \n",
       " \n",
       "                                         Instructions  \\\n",
       " 0  Complete the table below. Write ONE WORD AND /...   \n",
       " \n",
       "                                            Questions  \\\n",
       " 0  [1. Room _________, 2. _________ AM, 3. ______...   \n",
       " \n",
       "                                              Answers  \\\n",
       " 0  [105, 9:00, calculator, Thursday, 1:00, essays...   \n",
       " \n",
       "                                              Diagram  \\\n",
       " 0  ## University Lecture Schedule\\n\\n| Lecture Ti...   \n",
       " \n",
       "                                           Transcript  \n",
       " 0  NARRATOR: You will hear a conversation between...  ,\n",
       "   DateTime_Generated             Type  \\\n",
       " 0   2025_11_29_18_11  Form Completion   \n",
       " \n",
       "                                         Instructions  \\\n",
       " 0  Complete the form below. Write ONE WORD AND / ...   \n",
       " \n",
       "                                            Questions  \\\n",
       " 0  [University Lecture Series Registration Form, ...   \n",
       " \n",
       "                                      Answers Diagram  \\\n",
       " 0  [8546, Sociology, Robotics, Tuesday, 305]    None   \n",
       " \n",
       "                                           Transcript  \n",
       " 0  You will hear a conversation between a univers...  ,\n",
       "   DateTime_Generated           Type  \\\n",
       " 0   2025_11_29_18_13  Map Labelling   \n",
       " \n",
       "                                         Instructions  \\\n",
       " 0  Label the map below. Write the correct letter,...   \n",
       " \n",
       "                                            Questions          Answers  \\\n",
       " 0  [1. Bookshop, 2. Post Office, 3. Careers Servi...  [C, B, G, F, I]   \n",
       " \n",
       "                                              Diagram  \\\n",
       " 0  \\n                  North\\n                   ...   \n",
       " \n",
       "                                           Transcript  \n",
       " 0  You will hear a university staff member giving...  ,\n",
       "   DateTime_Generated                               Type  \\\n",
       " 0   2025_11_29_18_14  Multiple Choice - Multiple Choice   \n",
       " \n",
       "                                         Instructions  \\\n",
       " 0  You will hear a part of a university lecture a...   \n",
       " \n",
       "                                            Questions Answers Diagram  \\\n",
       " 0  [What TWO significant challenges does the lect...  [B, D]    None   \n",
       " \n",
       "                                           Transcript  \n",
       " 0  Examiner: You will hear a part of a university...  ,\n",
       "   DateTime_Generated                 Type  \\\n",
       " 0   2025_11_29_18_16  Sentence Completion   \n",
       " \n",
       "                                         Instructions  \\\n",
       " 0  Complete the sentences below. Write NO MORE TH...   \n",
       " \n",
       "                                            Questions  \\\n",
       " 0  [1. The traditional lecture format is often cr...   \n",
       " \n",
       "                                              Answers Diagram  \\\n",
       " 0  [passive reception, critical thinking, interac...    None   \n",
       " \n",
       "                                           Transcript  \n",
       " 0  You will hear a lecture from a university prof...  ]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated questions to processed_data/generated_question.csv\n",
      "All outputs saved to folder: set/set1\n"
     ]
    }
   ],
   "source": [
    "# Save to Flie\n",
    "def save_csv(df):\n",
    "    os.makedirs(\"model_training/processed_data\", exist_ok=True)\n",
    "    if os.path.exists(GENERATED_CSV):\n",
    "        df.to_csv(GENERATED_CSV, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(GENERATED_CSV, index=False)\n",
    "    print(f\"Saved generated questions to {GENERATED_CSV}\")\n",
    "\n",
    "def create_set_folder():\n",
    "    os.makedirs(\"set\", exist_ok=True)\n",
    "    existing = [d for d in os.listdir(\"set\") if d.startswith(\"set\")]\n",
    "    next_id = len(existing) + 1\n",
    "    folder_path = f\"set/set{next_id}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    return folder_path\n",
    "\n",
    "def write_text_files(folder, df):\n",
    "    sections = {\n",
    "        1: df.iloc[0],\n",
    "        2: df.iloc[1],\n",
    "        3: df.iloc[2],\n",
    "        4: df.iloc[3]\n",
    "    }\n",
    "\n",
    "    # Questions Only\n",
    "    with open(f\"{folder}/questions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sec, row in sections.items():\n",
    "            f.write(f\"Section {sec}\\n\")\n",
    "            f.write(\"Instructions:\\n\")\n",
    "            f.write(str(row[\"Instructions\"]) + \"\\n\\n\")\n",
    "            for q in row[\"Questions\"]:\n",
    "                f.write(str(q) + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # Full set: Instructions + Questions + Answers + Transcript\n",
    "    with open(f\"{folder}/full_set.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sec, row in sections.items():\n",
    "            f.write(f\"Section {sec}\\n\")\n",
    "\n",
    "            f.write(\"Instructions:\\n\")\n",
    "            f.write(str(row[\"Instructions\"]) + \"\\n\\n\")\n",
    "\n",
    "            f.write(\"Questions:\\n\")\n",
    "            for q in row[\"Questions\"]:\n",
    "                f.write(str(q) + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            f.write(\"Answers:\\n\")\n",
    "            for a in row[\"Answers\"]:\n",
    "                f.write(str(a) + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            f.write(\"Transcript:\\n\")\n",
    "            f.write(str(row[\"Transcript\"]) + \"\\n\")\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "    # Transcripts Only\n",
    "    with open(f\"{folder}/transcripts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sec, row in sections.items():\n",
    "            f.write(f\"Section {sec}\\n\")\n",
    "            f.write(str(row[\"Transcript\"]) + \"\\n\\n\")\n",
    "\n",
    "def save_all_outputs(questions):\n",
    "    if all(isinstance(q, pd.DataFrame) for q in questions):\n",
    "        df = pd.concat(questions, ignore_index=True)\n",
    "    else:\n",
    "        df = pd.DataFrame(questions)\n",
    "    \n",
    "    save_csv(df)\n",
    "    folder_path = create_set_folder()\n",
    "    write_text_files(folder_path, df)\n",
    "    print(f\"All outputs saved to folder: {folder_path}\")\n",
    "\n",
    "\n",
    "save_all_outputs(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d34bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
