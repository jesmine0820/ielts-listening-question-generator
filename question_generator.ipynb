{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf9f99b",
   "metadata": {},
   "source": [
    "# Question Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8249485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import textstat\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5539bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GenAI\n",
    "genai.configure(api_key=\"AIzaSyCSC0LPUznCj0USGxAVXjXT_4vgVqp-ah4\")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b42d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "QUESTION_TYPE_CSV = \"model_training/processed_data/questionType.csv\"\n",
    "GENERATED_JSON = \"model_training/processed_data/generated_questions.json\"\n",
    "WORD_CSV = \"model_training/processed_data/ielts_vocab.csv\"\n",
    "TRAINING_CSV = \"model_training/processed_data/training_set.csv\"\n",
    "TEMP_CSV = \"model_training/processed_data/temp_generated_questions.json\"\n",
    "\n",
    "MAX_ATTEMPT = 5\n",
    "REWARD_GOAL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "question_type_df = pd.read_csv(QUESTION_TYPE_CSV)\n",
    "common_vocab_df = pd.read_csv(WORD_CSV)\n",
    "training_df = pd.read_csv(TRAINING_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd58555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Data Only\n",
    "section_choices = {\n",
    "    1: [\n",
    "        {\n",
    "            \"typeID\": \"T001\",\n",
    "            \"theme\": \"Booking a hotel room\",\n",
    "            \"topic\": \"Asking about room facilities\",\n",
    "            \"spec\": \"Include questions about availability and prices.\"\n",
    "        }\n",
    "    ],\n",
    "    2: [\n",
    "        {\n",
    "            \"typeID\": \"T004\",\n",
    "            \"theme\": \"Campus tour\",\n",
    "            \"topic\": \"Identifying main buildings\",\n",
    "            \"spec\": \"Include left/right directions.\"\n",
    "        }\n",
    "    ],\n",
    "    3: [\n",
    "        {\n",
    "            \"typeID\": \"T006\",\n",
    "            \"theme\": \"Group project planning\",\n",
    "            \"topic\": \"Assigning tasks\",\n",
    "            \"spec\": \"Include four students.\"\n",
    "        }\n",
    "    ],\n",
    "    4: [\n",
    "        {\n",
    "            \"typeID\": \"T009\",\n",
    "            \"theme\": \"AI in communication\",\n",
    "            \"topic\": \"Impact of AI\",\n",
    "            \"spec\": \"Use academic style and one real example.\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7008e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert IELTS Listening question generator.\n",
    "Create realistic IELTS Listening questions and transcripts following the official format.\n",
    "\n",
    "--- QUESTION REQUIREMENTS ---\n",
    "Section: {section}\n",
    "Question Type: {typeID} - {type_name}\n",
    "Question Numbers: {question_range}\n",
    "Number of Questions: {question_count}\n",
    "\n",
    "Theme: {theme}\n",
    "Specific Topic: {specific_topic}\n",
    "Additional Specifications from Test Creator: {specifications}\n",
    "\n",
    "Instructions to Display: {instruction}\n",
    "Expected Answer Format: {answer_format}\n",
    "Format Rules: {format}\n",
    "Key Listening Skills: {key_skills}\n",
    "Typical Duration: {avg_duration}\n",
    "Expected Transcript Length: {avg_script_length} words\n",
    "Audio Speed: {audio_speed}\n",
    "Key Features: {key_features}\n",
    "\n",
    "--- OUTPUT REQUIREMENTS ---\n",
    "1. Produce exactly {question_count} questions.\n",
    "2. Output MUST be valid JSON ONLY, with these keys:\n",
    "   \"Section\", \"Type\", \"Instructions\", \"Diagram\",\n",
    "   \"Questions\", \"Answers\", \"Options\", \"Transcript\".\n",
    "3. \"Questions\" must be a list of strings.\n",
    "4. \"Answers\" must be a list of strings of equal length.\n",
    "5. For multiple-choice types, include \"Options\" (list of lists).\n",
    "6. The diagram should be drawn in the characters and plain text only.\n",
    "7. Transcript MUST naturally reference ALL question numbers in {question_range}.\n",
    "8. No Markdown. No explanations. JSON ONLY.\n",
    "\n",
    "Return the JSON format only.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Parser\n",
    "def safe_json_parse(raw):\n",
    "    if not raw: return None\n",
    "    raw = raw.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    try:\n",
    "        return json.loads(raw)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dedddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Functions\n",
    "def calculate_readability_score(text):\n",
    "    return textstat.flesch_reading_ease(str(text))\n",
    "\n",
    "def is_in_average_word_count(text, section_label):\n",
    "    if not text: return False\n",
    "    words = re.findall(r'\\b\\w+\\b', str(text))\n",
    "    wc = len(words)\n",
    "    expected = {\n",
    "        \"Section 1\": (500, 700),\n",
    "        \"Section 2\": (600, 800),\n",
    "        \"Section 3\": (800, 1000),\n",
    "        \"Section 4\": (1000, 1200)\n",
    "    }\n",
    "    low, high = expected.get(section_label, (0, 99999))\n",
    "    return low <= wc <= high\n",
    "\n",
    "def calculate_common_word_ratio(text):\n",
    "    common_vocab = set(common_vocab_df[\"Words\"].str.lower())\n",
    "    words = [w.lower() for w in re.findall(r'\\b\\w+\\b', str(text))]\n",
    "    if not words: return 0\n",
    "    uncommon = [w for w in words if w not in common_vocab]\n",
    "    return len(uncommon) / len(words)\n",
    "\n",
    "def calculate_similarity(text):\n",
    "    existing_texts = []\n",
    "    if \"transcript\" in training_df.columns:\n",
    "        existing_texts += training_df[\"transcript\"].dropna().astype(str).tolist()\n",
    "    if os.path.exists(GENERATED_JSON):\n",
    "        with open(GENERATED_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            saved_data = json.load(f)\n",
    "            existing_texts += [item.get(\"Transcript\",\"\") for item in saved_data]\n",
    "    if not existing_texts:\n",
    "        return 0.0\n",
    "    corpus = existing_texts + [text]\n",
    "    vec = TfidfVectorizer().fit_transform(corpus)\n",
    "    sims = cosine_similarity(vec[-1], vec[:-1]).flatten()\n",
    "    return max(sims) if len(sims) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca600029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question number calculation\n",
    "def get_question_counts(types):\n",
    "    if len(types) == 1:\n",
    "        return {types[0]: 10}\n",
    "    return {types[0]: 5, types[1]: 5}\n",
    "\n",
    "def number_ranges(counts, section_num):\n",
    "    start = (section_num - 1) * 10 + 1\n",
    "    ranges = {}\n",
    "    cur = start\n",
    "    for t, c in counts.items():\n",
    "        ranges[t] = f\"{cur}-{cur+c-1}\"\n",
    "        cur += c\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Call\n",
    "def model_generate(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return safe_json_parse(response.text)\n",
    "\n",
    "def generate_full_set(section_choices):\n",
    "    all_results = []\n",
    "\n",
    "    dt_key = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "    for section_label, entries in section_choices.items():\n",
    "        section_num = int(re.search(r\"\\d+\", str(section_label)).group())\n",
    "        # Map typeIDs to counts\n",
    "        types = [e[\"typeID\"] for e in entries]\n",
    "        counts = get_question_counts(types)\n",
    "        ranges = number_ranges(counts, section_num)\n",
    "\n",
    "        for entry in entries:\n",
    "            typeID = entry[\"typeID\"]\n",
    "            theme = entry[\"theme\"]\n",
    "            topic = entry[\"topic\"]\n",
    "            spec = entry[\"spec\"]\n",
    "\n",
    "            # Find the type info by typeID\n",
    "            type_row = question_type_df[question_type_df[\"typeID\"] == typeID]\n",
    "            if type_row.empty:\n",
    "                print(f\" WARNING: typeID '{typeID}' not found in question_type_df. Using placeholder info.\")\n",
    "                type_info = {\n",
    "                    \"type\": f\"Unknown Type ({typeID})\",\n",
    "                    \"instruction\": \"Follow standard instructions.\",\n",
    "                    \"answer_format\": \"List of answers\",\n",
    "                    \"format\": \"Text\",\n",
    "                    \"key_skills\": \"Listening\",\n",
    "                    \"avg_duration\": \"3-4 min\",\n",
    "                    \"avg_script_length\": \"600\",\n",
    "                    \"key_features\": \"IELTS standard\",\n",
    "                    \"audio_speed\": \"Normal\"\n",
    "                }\n",
    "            else:\n",
    "                type_info = type_row.iloc[0]\n",
    "\n",
    "            q_type_name = type_info[\"type\"]\n",
    "            question_count = counts[typeID]\n",
    "            question_range = ranges[typeID]\n",
    "\n",
    "            best_reward = -99\n",
    "            best_json = None\n",
    "\n",
    "            for attempt in range(1, MAX_ATTEMPT + 1):\n",
    "                print(f\"\\n[GENERATING] {section_label} - {q_type_name} Attempt {attempt}\")\n",
    "\n",
    "                prompt = PROMPT_TEMPLATE.format(\n",
    "                    section=section_label,\n",
    "                    question_range=question_range,\n",
    "                    question_count=question_count,\n",
    "                    typeID=typeID,\n",
    "                    type_name=q_type_name,\n",
    "                    theme=theme,\n",
    "                    specific_topic=topic,\n",
    "                    specifications=spec,\n",
    "                    instruction=type_info[\"instruction\"],\n",
    "                    answer_format=type_info[\"answer_format\"],\n",
    "                    format=type_info[\"format\"],\n",
    "                    key_skills=type_info[\"key_skills\"],\n",
    "                    avg_duration=type_info[\"avg_duration\"],\n",
    "                    avg_script_length=type_info[\"avg_script_length\"],\n",
    "                    key_features=type_info[\"key_features\"],\n",
    "                    audio_speed=type_info[\"audio_speed\"],\n",
    "                )\n",
    "\n",
    "                model_json = model_generate(prompt)\n",
    "\n",
    "                if not isinstance(model_json, dict):\n",
    "                    print(\"  Invalid JSON, using placeholder\")\n",
    "                    continue\n",
    "\n",
    "                transcript = model_json.get(\"Transcript\", \"\")\n",
    "                reward = 0\n",
    "                if calculate_readability_score(transcript) >= 55: reward += 1\n",
    "                if is_in_average_word_count(transcript, section_label): reward += 1\n",
    "                if calculate_common_word_ratio(transcript) >= 0.1: reward += 1\n",
    "                if calculate_similarity(transcript) <= 0.85: reward += 1\n",
    "\n",
    "                print(f\" -> Reward: {reward}\")\n",
    "\n",
    "                if reward > best_reward:\n",
    "                    best_reward = reward\n",
    "                    best_json = model_json\n",
    "\n",
    "                if reward == REWARD_GOAL:\n",
    "                    break\n",
    "\n",
    "            # Fallback placeholder\n",
    "            if best_json is None:\n",
    "                best_json = {\n",
    "                    \"Section\": section_label,\n",
    "                    \"Type\": q_type_name,\n",
    "                    \"Instructions\": type_info[\"instruction\"],\n",
    "                    \"Diagram\": None,\n",
    "                    \"Questions\": [f\"Placeholder Q{i}\" for i in range(1, question_count+1)],\n",
    "                    \"Answers\": [f\"Answer_{i}\" for i in range(1, question_count+1)],\n",
    "                    \"Options\": [None]*question_count,\n",
    "                    \"Transcript\": f\"Placeholder transcript {question_range}\"\n",
    "                }\n",
    "\n",
    "            all_results.append(best_json)\n",
    "\n",
    "    wrapped_output = {dt_key: all_results}\n",
    "\n",
    "    # Save temp copy\n",
    "    with open(TEMP_CSV, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(wrapped_output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Save or append into master JSON\n",
    "    if os.path.exists(GENERATED_JSON):\n",
    "        with open(GENERATED_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            existing = json.load(f)\n",
    "    else:\n",
    "        existing = {}\n",
    "\n",
    "    existing[dt_key] = all_results\n",
    "\n",
    "    with open(GENERATED_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(existing, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n Full question set saved under key {dt_key} in {GENERATED_JSON}\")\n",
    "    return wrapped_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Pipeline\n",
    "questions = generate_full_set(section_choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310abfb0",
   "metadata": {},
   "source": [
    "# View Question Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68bc03",
   "metadata": {},
   "source": [
    "# Save to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea6fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8096b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "TEMP_JSON = \"model_training/processed_data/temp_generated_questions.json\"\n",
    "\n",
    "DEJAVUSANS_FONT = \"frontend/fonts/DejaVuSans.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine next set folder\n",
    "# Make sure the the folder exists\n",
    "base_folder = \"sets\"\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "# Find existing set numbers\n",
    "existing = [int(re.search(r\"set(\\d+)\", d).group(1)) for d in os.listdir(base_folder) if re.match(r\"set\\d+\", d)]\n",
    "next_set = max(existing, default=0) + 1\n",
    "set_folder = os.path.join(base_folder, f\"set{next_set}\")\n",
    "os.makedirs(set_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0340542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Class\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"DejaVu\", \"B\", 12)\n",
    "        self.cell(0, 10, \"Generated Questions\", ln=True, align=\"C\")\n",
    "        self.ln(5)\n",
    "\n",
    "    def add_section(self, section_data, include_answers=True, include_transcript=True):\n",
    "        # Part header\n",
    "        self.set_font(\"DejaVu\", \"B\", 11)\n",
    "        self.cell(0, 8, f\"Part {section_data['Section']} - {section_data['Type']}\", ln=True)\n",
    "\n",
    "        # Instructions\n",
    "        self.set_font(\"DejaVu\", \"\", 10)\n",
    "        self.multi_cell(0, 6, f\"Instructions: {section_data['Instructions']}\")\n",
    "        \n",
    "        # Diagram if exists\n",
    "        if section_data.get(\"Diagram\") and section_data[\"Diagram\"].strip() != \"\":\n",
    "            self.multi_cell(0, 6, f\"Diagram:\\n{section_data['Diagram']}\")\n",
    "        self.ln(2)\n",
    "\n",
    "        # Questions (+ answers if requested)\n",
    "        for i, q in enumerate(section_data[\"Questions\"], start=1):\n",
    "            text = f\"{section_data['Section']}.{i}. {q}\"\n",
    "            if include_answers:\n",
    "                text += f\"  â†’ Answer: {section_data['Answers'][i-1]}\"\n",
    "            self.multi_cell(0, 6, text)\n",
    "        self.ln(3)\n",
    "\n",
    "        # Transcript\n",
    "        if include_transcript and section_data.get(\"Transcript\"):\n",
    "            self.multi_cell(0, 6, f\"Transcript:\\n{section_data['Transcript']}\")\n",
    "        self.add_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f41922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Full Set PDF\n",
    "pdf_full = PDF()\n",
    "pdf_full.add_font(\"DejaVu\", \"\", DEJAVUSANS_FONT, uni=True)\n",
    "pdf_full.add_font(\"DejaVu\", \"B\", DEJAVUSANS_FONT, uni=True)\n",
    "pdf_full.set_auto_page_break(auto=True, margin=15)\n",
    "pdf_full.add_page()\n",
    "pdf_full.set_font(\"DejaVu\", \"\", 10)\n",
    "\n",
    "for section in data:\n",
    "    pdf_full.add_section(section, include_answers=True, include_transcript=True)\n",
    "\n",
    "pdf_full_path = os.path.join(set_folder, \"full_set.pdf\")\n",
    "pdf_full.output(pdf_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0821ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Questoins Only PDF\n",
    "pdf_q = PDF()\n",
    "pdf_q.add_font(\"DejaVu\", \"\", DEJAVUSANS_FONT, uni=True)\n",
    "pdf_q.add_font(\"DejaVu\", \"B\", DEJAVUSANS_FONT, uni=True)\n",
    "pdf_q.set_auto_page_break(auto=True, margin=15)\n",
    "pdf_q.add_page()\n",
    "pdf_q.set_font(\"DejaVu\", \"\", 10)\n",
    "\n",
    "for section in data:\n",
    "    pdf_q.add_section(section, include_answers=False, include_transcript=False)\n",
    "\n",
    "pdf_q_path = os.path.join(set_folder, \"questions_only.pdf\")\n",
    "pdf_q.output(pdf_q_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transcript Only TXT\n",
    "trans_path = os.path.join(set_folder, \"transcripts_only.txt\")\n",
    "with open(trans_path, \"w\", encoding=\"utf-8\") as f_trans:\n",
    "    for section in data:\n",
    "        f_trans.write(f\"Part {section['Section']}\\n\")\n",
    "        f_trans.write(section.get(\"Transcript\", \"\") + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d28816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Questions Only TXT\n",
    "questions_txt_path = os.path.join(set_folder, \"questions_only.txt\")\n",
    "with open(questions_txt_path, \"w\", encoding=\"utf-8\") as f_qtxt:\n",
    "    for section in data:\n",
    "        f_qtxt.write(f\"Part {section['Section']} - {section['Type']}\\n\")\n",
    "        f_qtxt.write(f\"Instructions: {section['Instructions']}\\n\")\n",
    "        \n",
    "        # Diagram if exists\n",
    "        if section.get(\"Diagram\") and section[\"Diagram\"].strip() != \"\":\n",
    "            f_qtxt.write(f\"Diagram:\\n{section['Diagram']}\\n\")\n",
    "        \n",
    "        for i, q in enumerate(section[\"Questions\"], start=1):\n",
    "            f_qtxt.write(f\"{section['Section']}.{i}. {q}\\n\")\n",
    "        f_qtxt.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
