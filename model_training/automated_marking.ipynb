{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64cb7734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
      "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n",
      "mediapipe 0.10.21 requires protobuf<5,>=4.25.3, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai PyMuPDF easyocr pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc66a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Reading official marking key ---\n",
      "--- Step 2: Extracting student texts ---\n",
      "Reading: marking_data/set1_1.pdf...\n",
      "Reading: marking_data/set1_2.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Marking 2 students in batches ---\n",
      "Marking batch 1...\n",
      "\n",
      "--- PDF Report Generated: Marking_Summary.pdf ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import easyocr\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from fpdf import FPDF\n",
    "import io\n",
    "\n",
    "# 1. Setup Gemini with JSON Mode\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyBHbB9NlECSo8bQGOtF-DD_ADtAJEcA4V0\"\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Initialize the model with JSON output configuration\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-2.5-flash', # Recommended for high-volume marking\n",
    "    generation_config={\"response_mime_type\": \"application/json\"}\n",
    ")\n",
    "\n",
    "# Initialize OCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_ielts_grade(mark_str):\n",
    "    \"\"\"Converts a mark like '23/40' into an approximate IELTS Band Score.\"\"\"\n",
    "    try:\n",
    "        score = int(mark_str.split('/')[0])\n",
    "        if score >= 39: return \"9.0\"\n",
    "        if score >= 37: return \"8.5\"\n",
    "        if score >= 35: return \"8.0\"\n",
    "        if score >= 32: return \"7.5\"\n",
    "        if score >= 30: return \"7.0\"\n",
    "        if score >= 26: return \"6.5\"\n",
    "        if score >= 23: return \"6.0\"\n",
    "        if score >= 18: return \"5.5\"\n",
    "        if score >= 16: return \"5.0\"\n",
    "        if score >= 13: return \"4.5\"\n",
    "        return \"4.0 or below\"\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def extract_text_from_upload(file_path):\n",
    "    if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        results = reader.readtext(file_path, detail=0)\n",
    "        return \" \".join(results)\n",
    "    elif file_path.lower().endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    return \"\"\n",
    "\n",
    "def mark_batch_answers(official_key_text, student_data_list):\n",
    "    # Format student data for the prompt\n",
    "    students_input_str = \"\"\n",
    "    for i, text in enumerate(student_data_list):\n",
    "        students_input_str += f\"\\n--- STUDENT {i+1} ---\\n{text}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an IELTS Examiner. Use the provided Official Question Set as the absolute source of truth.\n",
    "    \n",
    "    OFFICIAL SET (Questions and Answers):\n",
    "    {official_key_text}\n",
    "    \n",
    "    TASK:\n",
    "    Mark the following {len(student_data_list)} students.\n",
    "    1. Identify each candidate's name.\n",
    "    2. Mark their answers (1 to 40).\n",
    "    3. Calculate total marks.\n",
    "    \n",
    "    STUDENT INPUTS:\n",
    "    {students_input_str}\n",
    "    \n",
    "    OUTPUT FORMAT (Strict JSON Array of Objects):\n",
    "    [\n",
    "      {{\n",
    "        \"candidate_name\": \"Full Name\",\n",
    "        \"total_marks\": \"X/40\",\n",
    "        \"correct_answers\": {{ \"1\": \"val\" }},\n",
    "        \"incorrect_answers\": {{ \"3\": {{ \"student_answer\": \"val\", \"correct_answer\": \"val\" }} }}\n",
    "      }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def export_results_to_pdf(results, official_file_path, output_filename=\"Marking_Summary.pdf\"):\n",
    "    folder_dir = os.path.dirname(official_file_path)\n",
    "    folder_name = os.path.basename(folder_dir.rstrip('/'))\n",
    "    set_label = folder_name.replace(\"set\", \"Set \")\n",
    "    current_time = datetime.now().strftime(\"%d %B %Y, %I:%M %p\")\n",
    "\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Header\n",
    "    pdf.set_font(\"Arial\", 'B', 20)\n",
    "    pdf.cell(0, 15, txt=set_label, ln=True, align='C')\n",
    "    pdf.set_font(\"Arial\", 'I', 11)\n",
    "    pdf.cell(0, 5, txt=current_time, ln=True, align='C')\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    # Table Header\n",
    "    pdf.set_font(\"Arial\", 'B', 11)\n",
    "    pdf.set_fill_color(231, 16, 16)\n",
    "    pdf.set_text_color(255, 255, 255)\n",
    "    pdf.cell(90, 12, txt=\" Candidate Name\", border=1, ln=0, fill=True)\n",
    "    pdf.cell(50, 12, txt=\" Mark\", border=1, ln=0, fill=True, align='C')\n",
    "    pdf.cell(50, 12, txt=\" Grade (Band)\", border=1, ln=1, fill=True, align='C')\n",
    "    \n",
    "    # Table Rows\n",
    "    pdf.set_font(\"Arial\", '', 11)\n",
    "    pdf.set_text_color(0, 0, 0)\n",
    "    for entry in results:\n",
    "        name = entry.get(\"candidate_name\", \"Unknown\")\n",
    "        mark = entry.get(\"total_marks\", \"0/40\")\n",
    "        grade = get_ielts_grade(mark)\n",
    "        pdf.cell(90, 10, txt=f\" {name}\", border=1, ln=0)\n",
    "        pdf.cell(50, 10, txt=str(mark), border=1, ln=0, align='C')\n",
    "        pdf.cell(50, 10, txt=str(grade), border=1, ln=1, align='C')\n",
    "\n",
    "    pdf.output(output_filename)\n",
    "    print(f\"\\n--- PDF Report Generated: {output_filename} ---\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "official_file = \"sets/set1/full_set.pdf\"\n",
    "student_uploads = [\n",
    "    \"marking_data/set1_1.pdf\",\n",
    "    \"marking_data/set1_2.jpg\"\n",
    "    # ... add up to 10 more here\n",
    "]\n",
    "\n",
    "# 1. Extract official key\n",
    "print(\"--- Step 1: Reading official marking key ---\")\n",
    "official_text = extract_text_from_pdf(official_file)\n",
    "\n",
    "# 2. Extract all student texts first\n",
    "print(\"--- Step 2: Extracting student texts ---\")\n",
    "batch_texts = []\n",
    "for upload in student_uploads:\n",
    "    if os.path.exists(upload):\n",
    "        print(f\"Reading: {upload}...\")\n",
    "        batch_texts.append(extract_text_from_upload(upload))\n",
    "\n",
    "# 3. Process in batches (up to 10 students per prompt)\n",
    "all_results = []\n",
    "batch_size = 10\n",
    "\n",
    "print(f\"--- Step 3: Marking {len(batch_texts)} students in batches ---\")\n",
    "for i in range(0, len(batch_texts), batch_size):\n",
    "    current_batch = batch_texts[i : i + batch_size]\n",
    "    print(f\"Marking batch {i//batch_size + 1}...\")\n",
    "    \n",
    "    raw_response = mark_batch_answers(official_text, current_batch)\n",
    "    \n",
    "    try:\n",
    "        batch_json = json.loads(raw_response.strip())\n",
    "        if isinstance(batch_json, list):\n",
    "            all_results.extend(batch_json)\n",
    "        else:\n",
    "            all_results.append(batch_json)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error parsing batch starting at index {i}\")\n",
    "\n",
    "# 4. Final Output\n",
    "if all_results:\n",
    "    export_results_to_pdf(all_results, official_file)\n",
    "else:\n",
    "    print(\"No results processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2ea8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
