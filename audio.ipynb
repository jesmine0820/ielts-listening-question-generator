{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ffea01",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28254f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "\n",
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize genai\n",
    "genai.configure(api_key=\"AIzaSyBS-2pbdjYouOkcqHaX4ZI5HHPpSSmq3iw\")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "def detect_gender(name):\n",
    "    prompt = f\"Determine the gender of this person from their name: {name}. Answer 'male' or 'female'.\"\n",
    "    response = model.generate_content(prompt)\n",
    "    text = response.text.lower()\n",
    "    if \"female\" in text:\n",
    "        return \"female\"\n",
    "    else:\n",
    "        return \"male\"\n",
    "    \n",
    "model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "tts = TTS(model_name)\n",
    "\n",
    "# Get available speakers\n",
    "all_speakers = tts.speakers\n",
    "\n",
    "# Split speakers into male/female\n",
    "male_speakers = [s for s in all_speakers if any(n in s.lower() for n in [\"david\",\"andrew\",\"badr\",\"damien\",\"gilberto\",\"ilkin\",\"kazuhiko\",\"ludvig\",\"suad\",\"torcull\",\"viktor\",\"zacharie\",\"xavier\",\"luis\",\"marcos\"])]\n",
    "female_speakers = [s for s in all_speakers if any(n in s.lower() for n in [\"claribel\",\"daisy\",\"tammie\",\"alison\",\"ana\",\"annmarie\",\"asya\",\"brenda\",\"gitta\",\"henriette\",\"sofia\",\"tammy\",\"tanja\",\"nova\",\"maja\",\"uta\",\"lidiya\",\"chandra\",\"szofi\",\"camilla\",\"lilya\",\"zofija\",\"narelle\",\"barbora\",\"alexandra\",\"alma\",\"rosemary\",\"ige\",\"filip\",\"damjan\",\"vjollca\"])]\n",
    "narrator_voice = \"Gracie Wise\"\n",
    "\n",
    "transcript_file = \"set/set1/transcripts.txt\"\n",
    "with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "\n",
    "sections = []\n",
    "current_section = []\n",
    "for line in lines:\n",
    "    if line.lower().startswith(\"section\"):\n",
    "        if current_section:\n",
    "            sections.append(current_section)\n",
    "            current_section = []\n",
    "    current_section.append(line)\n",
    "if current_section:\n",
    "    sections.append(current_section)\n",
    "\n",
    "final_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "for section_idx, section_lines in enumerate(sections):\n",
    "    section_audio = AudioSegment.silent(duration=0)\n",
    "    \n",
    "    # Parse lines into (speaker, text)\n",
    "    speaker_lines = []\n",
    "    for line in section_lines:\n",
    "        if ':' in line:\n",
    "            speaker, text = line.split(':', 1)\n",
    "            speaker_lines.append((speaker.strip(), text.strip()))\n",
    "        else:\n",
    "            speaker_lines.append(('NARRATOR', line.strip()))\n",
    "    \n",
    "    # Cache speaker -> assigned voice\n",
    "    speaker_voice_map = {}\n",
    "    \n",
    "    # Generate TTS for the section once\n",
    "    print(f\"Processing Section {section_idx+1}...\")\n",
    "    for speaker, text in tqdm(speaker_lines, desc=f\"Section {section_idx+1} lines\"):\n",
    "        # Assign voice\n",
    "        if speaker == \"NARRATOR\":\n",
    "            voice_name = narrator_voice\n",
    "        else:\n",
    "            if speaker not in speaker_voice_map:\n",
    "                gender = detect_gender(speaker)\n",
    "                if gender == \"male\":\n",
    "                    voice_name = male_speakers[hash(speaker) % len(male_speakers)]\n",
    "                else:\n",
    "                    voice_name = female_speakers[hash(speaker) % len(female_speakers)]\n",
    "                speaker_voice_map[speaker] = voice_name\n",
    "            else:\n",
    "                voice_name = speaker_voice_map[speaker]\n",
    "\n",
    "        # Generate TTS for this line\n",
    "        temp_wav = f\"temp_{section_idx}_{hash(speaker+text)}.wav\"\n",
    "        tts.tts_to_file(language=\"en\", text=text, speaker=voice_name, file_path=temp_wav)\n",
    "        \n",
    "        line_audio = AudioSegment.from_wav(temp_wav)\n",
    "        os.remove(temp_wav)\n",
    "        \n",
    "        # Add small pause after line (0.5 sec)\n",
    "        line_audio += AudioSegment.silent(duration=500)\n",
    "        \n",
    "        section_audio += line_audio\n",
    "    \n",
    "    # Repeat the section audio twice\n",
    "    section_audio = section_audio + section_audio\n",
    "    \n",
    "    # Add section pause (30 sec)\n",
    "    section_audio += AudioSegment.silent(duration=30000)\n",
    "    \n",
    "    final_audio += section_audio\n",
    "\n",
    "output_file = \"set/Set1/audio.wav\"\n",
    "final_audio.export(output_file, format=\"wav\")\n",
    "print(f\"Audio generated successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498cf3a4",
   "metadata": {},
   "source": [
    "## Modified Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030bddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cpu for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n",
      "W1130 21:15:14.613000 9472 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Section 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Section 1 lines: 100%|██████████| 20/20 [23:10<00:00, 69.53s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Section 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Section 2 lines: 100%|██████████| 30/30 [10:53<00:00, 21.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Section 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Section 3 lines: 100%|██████████| 16/16 [16:42<00:00, 62.64s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Section 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Section 4 lines: 100%|██████████| 13/13 [18:15<00:00, 84.31s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio generated successfully: set/Set1/audio.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import nltk\n",
    "import google.generativeai as genai\n",
    "\n",
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------------------\n",
    "# INITIAL SETUP\n",
    "# ----------------------------------------\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBS-2pbdjYouOkcqHaX4ZI5HHPpSSmq3iw\")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "tts = TTS(model_name)\n",
    "\n",
    "all_speakers = tts.speakers\n",
    "\n",
    "male_speakers = [s for s in all_speakers if any(n in s.lower() for n in [\n",
    "    \"david\", \"andrew\", \"badr\", \"damien\", \"gilberto\", \"ilkin\", \"kazuhiko\",\n",
    "    \"ludvig\", \"suad\", \"torcull\", \"viktor\", \"zacharie\", \"xavier\", \"luis\", \"marcos\"\n",
    "])]\n",
    "female_speakers = [s for s in all_speakers if any(n in s.lower() for n in [\n",
    "    \"claribel\", \"daisy\", \"tammie\", \"alison\", \"ana\", \"annmarie\", \"asya\", \"brenda\",\n",
    "    \"gitta\", \"henriette\", \"sofia\", \"tammy\", \"tanja\", \"nova\", \"maja\", \"uta\",\n",
    "    \"lidiya\", \"chandra\", \"szofi\", \"camilla\", \"lilya\", \"zofija\", \"narelle\",\n",
    "    \"barbora\", \"alexandra\", \"alma\", \"rosemary\", \"ige\", \"filip\", \"damjan\", \"vjollca\"\n",
    "])]\n",
    "narrator_voice = \"Gracie Wise\"\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# FUNCTIONS\n",
    "# ----------------------------------------\n",
    "\n",
    "def detect_gender(name):\n",
    "    \"\"\"Use Gemini API to detect gender\"\"\"\n",
    "    prompt = f\"Determine the gender of this person from their name: {name}. Answer only 'male' or 'female'.\"\n",
    "    response = model.generate_content(prompt)\n",
    "    text = response.text.lower()\n",
    "    return \"female\" if \"female\" in text else \"male\"\n",
    "\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Split text into sentences.\"\"\"\n",
    "    return nltk.sent_tokenize(text)\n",
    "\n",
    "\n",
    "def split_long_sentence(sentence, max_len=230):\n",
    "    \"\"\"Split long sentences into smaller parts.\"\"\"\n",
    "    if len(sentence) <= max_len:\n",
    "        return [sentence]\n",
    "\n",
    "    parts = []\n",
    "\n",
    "    # Try splitting by commas first\n",
    "    chunks = [c.strip() for c in sentence.split(\",\")]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if len(chunk) <= max_len:\n",
    "            parts.append(chunk)\n",
    "        else:\n",
    "            # Split by words\n",
    "            words = chunk.split()\n",
    "            current = \"\"\n",
    "            for w in words:\n",
    "                if len(current) + len(w) + 1 <= max_len:\n",
    "                    current += (\" \" + w if current else w)\n",
    "                else:\n",
    "                    parts.append(current)\n",
    "                    current = w\n",
    "            if current:\n",
    "                parts.append(current)\n",
    "    return parts\n",
    "\n",
    "\n",
    "def safe_split_text(text):\n",
    "    \"\"\"Split text -> sentences -> smaller chunks.\"\"\"\n",
    "    final = []\n",
    "    sentences = split_into_sentences(text)\n",
    "\n",
    "    for s in sentences:\n",
    "        final.extend(split_long_sentence(s))\n",
    "    return final\n",
    "\n",
    "\n",
    "def load_transcript_sections(filepath):\n",
    "    \"\"\"Load transcript file and split by sections.\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    sections = []\n",
    "    current = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"section\"):\n",
    "            if current:\n",
    "                sections.append(current)\n",
    "                current = []\n",
    "        current.append(line)\n",
    "\n",
    "    if current:\n",
    "        sections.append(current)\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "def parse_speaker_lines(section_lines):\n",
    "    \"\"\"Convert lines into (speaker, text).\"\"\"\n",
    "    result = []\n",
    "    for line in section_lines:\n",
    "        if \":\" in line:\n",
    "            speaker, text = line.split(\":\", 1)\n",
    "            result.append((speaker.strip(), text.strip()))\n",
    "        else:\n",
    "            result.append((\"NARRATOR\", line.strip()))\n",
    "    return result\n",
    "\n",
    "\n",
    "def assign_voice(speaker, speaker_voice_map):\n",
    "    \"\"\"Get or assign a voice based on gender.\"\"\"\n",
    "    if speaker == \"NARRATOR\":\n",
    "        return narrator_voice\n",
    "\n",
    "    if speaker in speaker_voice_map:\n",
    "        return speaker_voice_map[speaker]\n",
    "\n",
    "    gender = detect_gender(speaker)\n",
    "    if gender == \"male\":\n",
    "        voice = male_speakers[hash(speaker) % len(male_speakers)]\n",
    "    else:\n",
    "        voice = female_speakers[hash(speaker) % len(female_speakers)]\n",
    "\n",
    "    speaker_voice_map[speaker] = voice\n",
    "    return voice\n",
    "\n",
    "\n",
    "def generate_tts_chunk(text, voice, temp_name):\n",
    "    \"\"\"Generate a single TTS chunk.\"\"\"\n",
    "    tts.tts_to_file(\n",
    "        language=\"en\",\n",
    "        text=text,\n",
    "        speaker=voice,\n",
    "        file_path=temp_name\n",
    "    )\n",
    "    audio = AudioSegment.from_wav(temp_name)\n",
    "    os.remove(temp_name)\n",
    "    return audio\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# MAIN AUDIO GENERATION\n",
    "# ----------------------------------------\n",
    "\n",
    "transcript_file = \"set/set1/transcripts.txt\"\n",
    "sections = load_transcript_sections(transcript_file)\n",
    "\n",
    "final_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "for section_idx, section_lines in enumerate(sections):\n",
    "\n",
    "    print(f\"\\n--- Processing Section {section_idx + 1} ---\")\n",
    "    speaker_lines = parse_speaker_lines(section_lines)\n",
    "    speaker_voice_map = {}\n",
    "    section_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    for speaker, text in tqdm(speaker_lines, desc=f\"Section {section_idx+1} lines\"):\n",
    "\n",
    "        voice_name = assign_voice(speaker, speaker_voice_map)\n",
    "\n",
    "        # Split text into safe chunks\n",
    "        chunks = safe_split_text(text)\n",
    "\n",
    "        for chunk in chunks:\n",
    "            temp_wav = f\"temp_{section_idx}_{hash(speaker + chunk)}.wav\"\n",
    "            line_audio = generate_tts_chunk(chunk, voice_name, temp_wav)\n",
    "\n",
    "            # Add pause\n",
    "            line_audio += AudioSegment.silent(duration=400)\n",
    "            section_audio += line_audio\n",
    "\n",
    "    # Repeat section twice\n",
    "    section_audio = section_audio + section_audio\n",
    "\n",
    "    # Add 30 sec break\n",
    "    section_audio += AudioSegment.silent(duration=30000)\n",
    "\n",
    "    final_audio += section_audio\n",
    "\n",
    "\n",
    "output_file = \"set/Set1/audio.wav\"\n",
    "final_audio.export(output_file, format=\"wav\")\n",
    "\n",
    "print(f\"\\nAudio generated successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd590b7",
   "metadata": {},
   "source": [
    "## Slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219e3846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slower audio generated successfully: set/Set1/audio_slow.wav\n"
     ]
    }
   ],
   "source": [
    "# Slow down by 10% (0.9x speed)\n",
    "slower_audio = final_audio._spawn(final_audio.raw_data, overrides={\n",
    "    \"frame_rate\": int(final_audio.frame_rate * 0.95)\n",
    "}).set_frame_rate(final_audio.frame_rate)\n",
    "\n",
    "# Export the slower audio\n",
    "output_file = \"set/Set1/audio_slow.wav\"\n",
    "slower_audio.export(output_file, format=\"wav\")\n",
    "print(f\"Slower audio generated successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9993118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
