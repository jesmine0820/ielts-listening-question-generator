{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596c8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for continuous learning question generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d20ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Section 1': ['Plan Labelling', 'Form Completion'], 'Section 2': ['Multiple Choice', 'Map Labelling'], 'Section 3': ['Flow Chart Completion', 'Multiple Choice'], 'Section 4': ['Note Completion']}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import textstat\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize genai\n",
    "genai.configure(api_key=\"AIzaSyBS-2pbdjYouOkcqHaX4ZI5HHPpSSmq3iw\")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# Variable Initialization\n",
    "assignments = {}\n",
    "questions = []\n",
    "\n",
    "# Prompt Template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert IELTS Listening question generator.\n",
    "Generate a realistic IELTS Listening question according to the following details:\n",
    "\n",
    "Question Type: {typeID} - {type_name}\n",
    "Theme: {theme}\n",
    "Specific Topic: {specific_topic}\n",
    "Specifications: {specifications}\n",
    "Instructions: {instruction}\n",
    "Format: {format}\n",
    "Answer Format: {answer_format}\n",
    "Key Skills: {key_skills}\n",
    "Average Duration: {avg_duration}\n",
    "Average Script Length: {avg_script_length}\n",
    "Key Features: {key_features}\n",
    "Audio Speed: {audio_speed}\n",
    "\n",
    "Requirements:\n",
    "1. Generate questions, answers, and the audio transcript.\n",
    "2. If the question type requires a diagram (Map, Plan, Flow Chart), generate a simple diagram (as text description or URL placeholder).\n",
    "3. Return the output in JSON format:\n",
    "{{\n",
    "  \"Type\": [],\n",
    "  \"Instructions\": [],\n",
    "  \"Diagram\": [],\n",
    "  \"Questions\": [],\n",
    "  \"Answers\": [],\n",
    "  \"Transcript\": \"\"\n",
    "}}\n",
    "Type -> Question types with type names only\n",
    "Instructions -> Instructions for the question based on the references above\n",
    "Diagram -> Diagram description or URL placeholder (if applicable, else null)\n",
    "Questions -> List of questions\n",
    "Answers -> List of answers\n",
    "Transcript -> Full audio transcript. The transcript should include the introductions as a real IELTS Listening test.\n",
    "4. Ensure the JSON is properly formatted. Do not include any explanations or additional text outside the JSON.\n",
    "5. Do not add other fields other than the ones mentioned in the JSON format above.\n",
    "\"\"\"\n",
    "\n",
    "# Random choose question type\n",
    "def choose_question_type(input=\"processed_data/questionType.csv\"):\n",
    "    df = pd.read_csv(input)\n",
    "\n",
    "    for section in sorted(df['part'].unique()):\n",
    "        section_types = df[df['part'] == section]['type'].tolist()\n",
    "        k = random.choice([1,2])\n",
    "        selected = random.sample(section_types, k=min(k,len(section_types)))\n",
    "\n",
    "        assignments[f\"Section {section}\"] = selected\n",
    "\n",
    "# Parse JSON safety\n",
    "def safe_json_parse(response_text):\n",
    "    cleaned = re.sub(r\"```(?:json)?\", \"\", response_text)\n",
    "    cleaned = cleaned.replace(\"```\", \"\").strip()\n",
    "    match = re.search(r'\\{[\\s\\S]*\\}', cleaned)\n",
    "    if match:\n",
    "        cleaned = match.group(0)\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSON parsing failed. Raw model output:\\n\", response_text)\n",
    "        return None\n",
    "    \n",
    "# Generate question by using Gemini\n",
    "def generate_question(typeID, type_name, theme, specific_topic, specifications, instruction, answer_format, format, key_skills, avg_duration, avg_script_length, key_features, audio_speed):\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        typeID=typeID,\n",
    "        type_name=type_name,\n",
    "        theme=theme,\n",
    "        specific_topic=specific_topic,\n",
    "        specifications=specifications,\n",
    "        instruction=instruction,\n",
    "        answer_format=answer_format,\n",
    "        format=format,\n",
    "        key_skills=key_skills,\n",
    "        avg_duration=avg_duration,\n",
    "        avg_script_length=avg_script_length,\n",
    "        key_features=key_features,\n",
    "        audio_speed=audio_speed\n",
    "    )\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    clean_response = safe_json_parse(response.text)\n",
    "    \n",
    "    return clean_response\n",
    "\n",
    "# Generate each question\n",
    "def set_question(theme, specific_topic, specifications, input=\"processed_data/questionType.csv\"):\n",
    "    df = pd.read_csv(input)\n",
    "    for section, types in assignments.items():\n",
    "        print(f\"\\n{section} Questions:\")\n",
    "        for q_type in types:\n",
    "            type_info = df[df['type'] == q_type].iloc[0]\n",
    "            question_data = generate_question(\n",
    "                typeID=type_info['type'],\n",
    "                type_name=type_info['type'],\n",
    "                theme=theme,\n",
    "                specific_topic=specific_topic,\n",
    "                specifications=specifications,\n",
    "                instruction=type_info['instruction'],\n",
    "                answer_format=type_info['answer_format'],\n",
    "                format=type_info['format'],\n",
    "                key_skills=type_info['key_skills'],\n",
    "                avg_duration=type_info['avg_duration'],\n",
    "                avg_script_length=type_info['avg_script_length'],\n",
    "                key_features=type_info['key_features'],\n",
    "                audio_speed=type_info['audio_speed']\n",
    "            )\n",
    "            questions.append(question_data)\n",
    "            print(question_data)\n",
    "\n",
    "# Save to DataFrames\n",
    "def normalize_question(q):\n",
    "    if q is None:\n",
    "        return None\n",
    "    \n",
    "    clean = {}\n",
    "\n",
    "    clean['DateTime_Generated'] = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "    # Flatten Type\n",
    "    t = q.get(\"Type\")\n",
    "    if isinstance(t, list):\n",
    "        clean[\"Type\"] = \" \".join(str(x) for x in t)\n",
    "    else:\n",
    "        clean[\"Type\"] = t\n",
    "\n",
    "    # Flatten Instructions\n",
    "    instr = q.get(\"Instructions\")\n",
    "    if isinstance(instr, list):\n",
    "        clean[\"Instructions\"] = \" \".join(str(x) for x in instr)\n",
    "    else:\n",
    "        clean[\"Instructions\"] = instr\n",
    "\n",
    "    clean[\"Questions\"] = q.get(\"Questions\")\n",
    "    clean[\"Answers\"] = q.get(\"Answers\")\n",
    "    clean[\"Diagram\"] = q.get(\"Diagram\")\n",
    "    clean[\"Transcript\"] = q.get(\"Transcript\")\n",
    "\n",
    "    return clean\n",
    "\n",
    "def save_csv(df):\n",
    "    os.makedirs(\"processed_data\", exist_ok=True)\n",
    "    filename = \"processed_data/generated_question.csv\"\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        df.to_csv(filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Saved generated questions to {filename}\")\n",
    "\n",
    "def create_set_folder():\n",
    "    os.makedirs(\"set\", exist_ok=True)\n",
    "\n",
    "    existing = [d for d in os.listdir(\"set\") if d.startswith(\"set\")]\n",
    "    next_id = len(existing) + 1\n",
    "\n",
    "    folder_path = f\"set/set{next_id}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "def write_text_files(folder, df):\n",
    "    sections = {\n",
    "        1: df.iloc[0],\n",
    "        2: df.iloc[1],\n",
    "        3: df.iloc[2],\n",
    "        4: df.iloc[3]\n",
    "    }\n",
    "\n",
    "    # Questions Only\n",
    "    with open(f\"{folder}/questions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sec, row in sections.items():\n",
    "            f.write(f\"Section {sec}\\n\")\n",
    "            f.write(\"Instructions:\\n\")\n",
    "            f.write(str(row[\"Instructions\"]) + \"\\n\\n\")\n",
    "            for q in row[\"Questions\"]:\n",
    "                f.write(str(q) + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # Full set: Instructions + Questions + Answers + Transcript\n",
    "    with open(f\"{folder}/full_set.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sec, row in sections.items():\n",
    "            f.write(f\"Section {sec}\\n\")\n",
    "            f.write(\"Instructions:\\n\")\n",
    "            f.write(str(row[\"Instructions\"]) + \"\\n\\n\")\n",
    "\n",
    "            f.write(\"Questions:\\n\")\n",
    "            for q in row[\"Questions\"]:\n",
    "                f.write(str(q) + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            f.write(\"Answers:\\n\")\n",
    "            for a in row[\"Answers\"]:\n",
    "                f.write(str(a) + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            f.write(\"Transcript:\\n\")\n",
    "            f.write(str(row[\"Transcript\"]) + \"\\n\")\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "    # Transcripts Only\n",
    "    with open(f\"{folder}/transcripts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sec, row in sections.items():\n",
    "            f.write(f\"Section {sec}\\n\")\n",
    "            f.write(str(row[\"Transcript\"]) + \"\\n\\n\")\n",
    "\n",
    "def save_all_outputs(df):\n",
    "    save_csv(df)\n",
    "    create_set_folder()\n",
    "    existing = [d for d in os.listdir(\"set\") if d.startswith(\"set\")]\n",
    "    next_id = len(existing)\n",
    "    folder_path = f\"set/set{next_id}\"\n",
    "    write_text_files(folder_path, df)\n",
    "\n",
    "# Testing Purpose\n",
    "theme = \"Education\"\n",
    "specific_topic = \"University Lectures\"\n",
    "specifications = \"Academic context, formal tone\"\n",
    "\n",
    "# Main pipeline\n",
    "choose_question_type()\n",
    "set_question(theme, specific_topic, specifications)\n",
    "\n",
    "# Save to files\n",
    "question_df = pd.DataFrame([normalize_question(q) for q in questions])\n",
    "save_all_outputs(question_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fba035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
